<<<<<<< HEAD
fulldata <- readRDS("alzdata.rds")
if (!requireNamespace("pacman", quietly = TRUE)) install.packages("pacman"); library(pacman)
pacman::p_load(tidyverse, caret, ranger, tree, glmnet, ISLR, ggplot2, Matrix)
# read the cleaned Alzheimers dataset
alzdata <- readRDS("knnalzdata.RDS")
? train
set.seed(5003)
train_index <- createDataPartition(alzdata$Diagnosis, p = 0.7, list = FALSE)
train_data <- alzdata[train_index, ]
test_data <- alzdata[-train_index, ]
modelcv <- trainControl(
method = "repeatedcv",
number = 10,
repeats = 10,
search = "grid",
classProbs = TRUE,
summaryFunction = prSummary,
savePredictions = "all",
)
#model example for knn
###set.seed(5003)
###knn_model <- train(
### Diagnosis ~ .,
###data = train_data,
### method = "knn",
#tuneLength = 30,
###trControl = modelcv,
### preProcess = c("center", "scale"),
#metric = "AUC"
ntree_seq <- c(1, 50, 100, 400, 500, 700, 800, 900, 1000, 2000)
rf_grid <- train(
Diagnosis ~ .,
data = train_data,
method = "rf",
trControl = modelcv,
tuneGrid = expand.grid(.mtry = sqrt(ncol(train_data) - 1)),  # Default mtry, adjust as needed
ntree = ntree_seq
)
rf_grid <- train(
Diagnosis ~ .,
data = train_data,
method = "rf",
trControl = modelcv,
tuneGrid = expand.grid(.mtry = sqrt(ncol(train_data) - 1)),  # Default mtry, adjust as needed
ntree = 50
)
print(rf_grid$results)
rf_grid$results
View(rf_grid)
plot(rf_grid)
=======
? train
?train()
? train.
? train(x) \
??train
library(caret)
?train
>>>>>>> 7c6d8f9d6ad4865b9ede195acf6c9ef366d4d07f
if (!requireNamespace("pacman", quietly = TRUE)) install.packages("pacman"); library(pacman)
pacman::p_load(tidyverse, caret, ranger, tree, glmnet, ISLR, ggplot2, Matrix)
# read the cleaned Alzheimers dataset
alzdata <- readRDS("knnalzdata.RDS")
set.seed(5003)
train_index <- createDataPartition(alzdata$Diagnosis, p = 0.7, list = FALSE)
train_data <- alzdata[train_index, ]
test_data <- alzdata[-train_index, ]
modelcv <- trainControl(
method = "repeatedcv",
number = 10,
repeats = 10,
search = "grid",
classProbs = TRUE,
summaryFunction = prSummary,
savePredictions = "all",
)
#model example for knn
###set.seed(5003)
###knn_model <- train(
### Diagnosis ~ .,
###data = train_data,
### method = "knn",
#tuneLength = 30,
###trControl = modelcv,
### preProcess = c("center", "scale"),
#metric = "AUC"
<<<<<<< HEAD
ntree_seq <- c(1, 50, 100, 400, 500, 700, 800, 900, 1000, 2000)
max.ntree_seq <- max(ntree_seq)
test_diagnosis <- test_data[["Diagnosis"]]
rf_model <- train(
Diagnosis ~ .,
data = train_data,
method = "rf",
trControl = modelcv,
tuneGrid = expand.grid(.mtry = sqrt(ncol(train_data) - 1)),  # Default mtry, adjust as needed
ntree = max.ntree_seq
)
if (!requireNamespace("pacman", quietly = TRUE)) install.packages("pacman"); library(pacman)
pacman::p_load(tidyverse, caret, ranger, tree, glmnet, ISLR, ggplot2, Matrix)
# read the cleaned Alzheimers dataset
alzdata <- readRDS("knnalzdata.RDS")
set.seed(5003)
train_index <- createDataPartition(alzdata$Diagnosis, p = 0.7, list = FALSE)
train_data <- alzdata[train_index, ]
test_data <- alzdata[-train_index, ]
modelcv <- trainControl(
method = "repeatedcv",
number = 10,
repeats = 10,
search = "grid",
classProbs = TRUE,
summaryFunction = prSummary,
savePredictions = "all",
)
#model example for knn
###set.seed(5003)
###knn_model <- train(
### Diagnosis ~ .,
###data = train_data,
### method = "knn",
#tuneLength = 30,
###trControl = modelcv,
### preProcess = c("center", "scale"),
#metric = "AUC"
ntree_seq <- c(1, 50, 100, 400, 500)
max.ntree_seq <- max(ntree_seq)
test_diagnosis <- test_data[["Diagnosis"]]
rf_model <- train(
Diagnosis ~ .,
data = train_data,
method = "rf",
trControl = modelcv,
tuneGrid = expand.grid(.mtry = sqrt(ncol(train_data) - 1)),  # Default mtry, adjust as needed
ntree = max.ntree_seq
)
rand.forest.function <- function(x) {
predict_rf <- predict(rf_model, data = test_dat, num.trees = x)[["predictions"]]
predicted_labels <- ifelse(predict_rf[, "Alzheimers"] > 0.35, "Alzheimers", "No_Alzheimers") |> as.factor()
CM <- confusionMatrix(test_diagnosis, predicted_labels, positive = "Alzheimers")
Sensit <- CM$byClass[["Sensitivity"]]
Specif <- CM$byClass[["Specificity"]]
Accura <- CM$overall[["Accuracy"]]
TP <- CM$table["Alzheimers", "Alzheimers"]
FP <- CM$table["Alzheimers", "No_Alzheimers"]
FN <- CM$table["No_Alzheimers", "Alzheimers"]
precision <- TP / (TP + FP)
recall <- TP / (TP + FN)
F1 <- 2 * (precision * recall) / (precision + recall)
Performance_measures <- list(Sensitivity = Sensit, Specificity = Specif, Accuracy = Accura, F1 = F1)
}
perf_measures <- map(ntree_seq, rand.forest.function)
rand.forest.function <- function(x) {
predict_rf <- predict(rf_model, data = test_data, num.trees = x)[["predictions"]]
predicted_labels <- ifelse(predict_rf[, "Alzheimers"] > 0.35, "Alzheimers", "No_Alzheimers") |> as.factor()
CM <- confusionMatrix(test_diagnosis, predicted_labels, positive = "Alzheimers")
Sensit <- CM$byClass[["Sensitivity"]]
Specif <- CM$byClass[["Specificity"]]
Accura <- CM$overall[["Accuracy"]]
TP <- CM$table["Alzheimers", "Alzheimers"]
FP <- CM$table["Alzheimers", "No_Alzheimers"]
FN <- CM$table["No_Alzheimers", "Alzheimers"]
precision <- TP / (TP + FP)
recall <- TP / (TP + FN)
F1 <- 2 * (precision * recall) / (precision + recall)
Performance_measures <- list(Sensitivity = Sensit, Specificity = Specif, Accuracy = Accura, F1 = F1)
}
perf_measures <- map(ntree_seq, rand.forest.function)
View(test_data)
View(train_data)
setdiff(names(train_data), names(test_data))
test_data_rf <- test_data[ ,-"Diagnosis"]
? setdiff
head(test_data[,"Diagnosis"])
head(setdiff(test_data, test_data["Diagnosis"]))
test_data_rf <- test_data[, -which(names(test_data) == "Diagnosis")]
rand.forest.function <- function(x) {
predict_rf <- predict(rf_model, data = test_data_rf, num.trees = x)[["predictions"]]
predicted_labels <- ifelse(predict_rf[, "Alzheimers"] > 0.35, "Alzheimers", "No_Alzheimers") |> as.factor()
CM <- confusionMatrix(test_diagnosis, predicted_labels, positive = "Alzheimers")
Sensit <- CM$byClass[["Sensitivity"]]
Specif <- CM$byClass[["Specificity"]]
Accura <- CM$overall[["Accuracy"]]
TP <- CM$table["Alzheimers", "Alzheimers"]
FP <- CM$table["Alzheimers", "No_Alzheimers"]
FN <- CM$table["No_Alzheimers", "Alzheimers"]
precision <- TP / (TP + FP)
recall <- TP / (TP + FN)
F1 <- 2 * (precision * recall) / (precision + recall)
Performance_measures <- list(Sensitivity = Sensit, Specificity = Specif, Accuracy = Accura, F1 = F1)
}
perf_measures <- map(ntree_seq, rand.forest.function)
ntree_seq <- c(1, 50)
max.ntree_seq <- max(ntree_seq)
test_diagnosis <- test_data[["Diagnosis"]]
test_data_rf <- test_data[, -which(names(test_data) == "Diagnosis")]
rand.forest.function <- function(x) {
rf_model <- train(
Diagnosis ~ .,
data = train_data,
method = "rf",
trControl = modelcv,
tuneGrid = expand.grid(.mtry = sqrt(ncol(train_data) - 1)),
ntree = x
)
predict_rf <- predict(rf_model, data = test_data_rf, type = "prob")
predicted_labels <- ifelse(predict_rf[, "Alzheimers"] > 0.35, "Alzheimers", "No_Alzheimers") |> as.factor()
CM <- confusionMatrix(test_diagnosis, predicted_labels, positive = "Alzheimers")
Sensit <- CM$byClass[["Sensitivity"]]
Specif <- CM$byClass[["Specificity"]]
Accura <- CM$overall[["Accuracy"]]
TP <- CM$table["Alzheimers", "Alzheimers"]
FP <- CM$table["Alzheimers", "No_Alzheimers"]
FN <- CM$table["No_Alzheimers", "Alzheimers"]
precision <- TP / (TP + FP)
recall <- TP / (TP + FN)
F1 <- 2 * (precision * recall) / (precision + recall)
Performance_measures <- list(ntree = x, Sensitivity = Sensit, Specificity = Specif, Accuracy = Accura, F1 = F1)
}
perf_measures <- map(ntree_seq, rand.forest.function)
predict_rf <- predict(rf_model, data = test_data_rf, type = "prob")
predict_rf <- predict(rf_model, data = test_data, type = "prob")
View(rf_model)
View(train_data)
View(test_data)
predict_rf <- predict(rf_model, newdata = test_data, type = "prob")
ntree_seq <- c(1, 50)
max.ntree_seq <- max(ntree_seq)
test_diagnosis <- test_data[["Diagnosis"]]
rf_model <- train(
Diagnosis ~ .,
data = train_data,
method = "rf",
trControl = modelcv,
tuneGrid = expand.grid(.mtry = sqrt(ncol(train_data) - 1)),
ntree = max.ntree_seq
)
rand.forest.function <- function(x) {
predict_rf <- predict(rf_model, newdata = test_data, type = "prob", num.trees = x)
predicted_labels <- ifelse(predict_rf[, "Alzheimers"] > 0.35, "Alzheimers", "No_Alzheimers") |> as.factor()
CM <- confusionMatrix(test_diagnosis, predicted_labels, positive = "Alzheimers")
Sensit <- CM$byClass[["Sensitivity"]]
Specif <- CM$byClass[["Specificity"]]
Accura <- CM$overall[["Accuracy"]]
TP <- CM$table["Alzheimers", "Alzheimers"]
FP <- CM$table["Alzheimers", "No_Alzheimers"]
FN <- CM$table["No_Alzheimers", "Alzheimers"]
precision <- TP / (TP + FP)
recall <- TP / (TP + FN)
F1 <- 2 * (precision * recall) / (precision + recall)
Performance_measures <- list(Sensitivity = Sensit, Specificity = Specif, Accuracy = Accura, F1 = F1)
}
perf_measures <- map(ntree_seq, rand.forest.function)
View(perf_measures)
ntree_seq <- c(1, 50, 100, 200, 300, 400, 500)
max.ntree_seq <- max(ntree_seq)
test_diagnosis <- test_data[["Diagnosis"]]
rf_model <- train(
Diagnosis ~ .,
data = train_data,
method = "rf",
trControl = modelcv,
tuneGrid = expand.grid(.mtry = sqrt(ncol(train_data) - 1)),
ntree = max.ntree_seq
)
rand.forest.function <- function(x) {
predict_rf <- predict(rf_model, newdata = test_data, type = "prob", num.trees = x)
predicted_labels <- ifelse(predict_rf[, "Alzheimers"] > 0.35, "Alzheimers", "No_Alzheimers") |> as.factor()
CM <- confusionMatrix(test_diagnosis, predicted_labels, positive = "Alzheimers")
Sensit <- CM$byClass[["Sensitivity"]]
Specif <- CM$byClass[["Specificity"]]
Accura <- CM$overall[["Accuracy"]]
TP <- CM$table["Alzheimers", "Alzheimers"]
FP <- CM$table["Alzheimers", "No_Alzheimers"]
FN <- CM$table["No_Alzheimers", "Alzheimers"]
precision <- TP / (TP + FP)
recall <- TP / (TP + FN)
F1 <- 2 * (precision * recall) / (precision + recall)
Performance_measures <- list(Sensitivity = Sensit, Specificity = Specif, Accuracy = Accura, F1 = F1)
}
perf_measures <- map(ntree_seq, rand.forest.function)
View(perf_measures)
rand.forest.function <- function(x) {
rf_model <- train(
Diagnosis ~ .,
data = train_data,
method = "rf",
trControl = modelcv,
tuneGrid = expand.grid(.mtry = sqrt(ncol(train_data) - 1)),
ntree = x
)
predict_rf <- predict(rf_model, newdata = test_data, type = "prob")
predicted_labels <- ifelse(predict_rf[, "Alzheimers"] > 0.35, "Alzheimers", "No_Alzheimers") |> as.factor()
CM <- confusionMatrix(test_diagnosis, predicted_labels, positive = "Alzheimers")
Sensit <- CM$byClass[["Sensitivity"]]
Specif <- CM$byClass[["Specificity"]]
Accura <- CM$overall[["Accuracy"]]
TP <- CM$table["Alzheimers", "Alzheimers"]
FP <- CM$table["Alzheimers", "No_Alzheimers"]
FN <- CM$table["No_Alzheimers", "Alzheimers"]
precision <- TP / (TP + FP)
recall <- TP / (TP + FN)
F1 <- 2 * (precision * recall) / (precision + recall)
Performance_measures <- list(ntrees = x, Sensitivity = Sensit, Specificity = Specif, Accuracy = Accura, F1 = F1)
}
perf_measures <- map(ntree_seq, rand.forest.function)
View(perf_measures)
sensitivities <- map_dbl(perf_measures, "Sensitivity")
plot_data <- data.frame(ntree_seq, sensitivities)
lineplot <- ggplot(plot_data, aes(x = ntree_seq, y = sensitivities)) +
geom_line() +
geom_point() +
geom_text(aes(label = round(sensitivities, 4)),
vjust = -0.5,
color = "black",
size = 3.5) +
labs(x = "Number of Trees", y = "Sensitivity") +
theme_minimal()
lineplot <- ggplot(plot_data, aes(x = ntree_seq, y = sensitivities)) +
geom_line() +
geom_point() +
geom_text(aes(label = round(sensitivities, 4)),
vjust = -0.5,
color = "black",
size = 3.5) +
labs(x = "Number of Trees", y = "Sensitivity") +
theme_minimal()
ggplot(plot_data, aes(x = ntree_seq, y = sensitivities)) +
geom_line() +
geom_point() +
geom_text(aes(label = round(sensitivities, 4)),
vjust = -0.5,
color = "black",
size = 3.5) +
labs(x = "Number of Trees", y = "Sensitivity") +
theme_minimal()
perf_measures_df <- map_dfr(ntree_seq, function(x) {
perf <- rand.forest.function(x)
data.frame(ntree_seq = x,
Sensitivity = perf$Sensitivity,
Specificity = perf$Specificity,
Accuracy = perf$Accuracy,
F1 = perf$F1)
})
View(perf_measures)
data.frame(perf_measures)
df <- data.frame(perf_measures)
View(df)
str(perf_measures)
if (!requireNamespace("pacman", quietly = TRUE)) install.packages("pacman"); library(pacman)
pacman::p_load(tidyverse, caret, ranger, tree, glmnet, ISLR, ggplot2, Matrix, dplyr)
# read the cleaned Alzheimers dataset
alzdata <- readRDS("knnalzdata.RDS")
df <- bind_rows(perf_measures)
View(df)
perf_measures_df <- bind_rows(perf_measures)
perf_measures_long <- perf_measures_df %>%
pivot_longer(cols = c(Sensitivity, Specificity, Accuracy, F1),
names_to = "Measure",
values_to = "Value")
ggplot(perf_measures_long, aes(x = factor(ntree_seq), y = Value, fill = Measure)) +
geom_bar(stat = "identity", position = "dodge") +
labs(x = "Number of Trees", y = "Value") +
scale_fill_manual(values = c("#E09F3E", "#335C67", "#99A88C", "#E3DED1")) +
theme_minimal()
View(perf_measures_long)
perf_measures_long <- perf_measures_df %>%
pivot_longer(cols = c(ntrees, Sensitivity, Specificity, Accuracy, F1),
names_to = "Measure",
values_to = "Value")
View(perf_measures_long)
ggplot(perf_measures_long, aes(x = factor(ntree_seq), y = Value, fill = Measure)) +
geom_bar(stat = "identity", position = "dodge") +
labs(x = "Number of Trees", y = "Value") +
scale_fill_manual(values = c("#E09F3E", "#335C67", "#99A88C", "#E3DED1")) +
theme_minimal()
str(perf_measures_df)
perf_measures_long <- perf_measures_df %>%
pivot_longer(cols = c(Sensitivity, Specificity, Accuracy, F1),
names_to = "Measure",
values_to = "Value")
ggplot(perf_measures_long, aes(x = factor(ntrees), y = Value, fill = Measure)) +
geom_bar(stat = "identity", position = "dodge") +
labs(x = "Number of Trees", y = "Value") +
scale_fill_manual(values = c("#E09F3E", "#335C67", "#99A88C", "#E3DED1")) +
theme_minimal()
ggplot(perf_measures_long, aes(x = factor(ntrees), y = Value, fill = Measure)) +
geom_bar(stat = "identity", position = "dodge") +
labs(x = "Number of Trees", y = "Value") +
scale_fill_manual(values = c("#99A88C", "#335C67", "#E09F3E", "#E3DED1")) +
theme_minimal()
ggplot(perf_measures_long, aes(x = factor(ntrees), y = Value, fill = Measure)) +
geom_bar(stat = "identity", position = "dodge") +
geom_text(aes(label = sprintf("%.2f", Value)),
position = position_dodge(width = 0.8),
vjust = -0.5,
size = 3.5) +
labs(x = "Number of Trees", y = "Value") +
scale_fill_manual(values = c("#99A88C", "#335C67", "#E09F3E", "#E3DED1")) +
theme_minimal()
ggplot(perf_measures_long, aes(x = factor(ntrees), y = Value, fill = Measure)) +
geom_bar(stat = "identity", position = "dodge") +
geom_text(aes(label = sprintf("%.2f", Value)),
position = position_dodge(width = 0.8),
vjust = -0.5,
size = 1.5) +
labs(x = "Number of Trees", y = "Value") +
scale_fill_manual(values = c("#99A88C", "#335C67", "#E09F3E", "#E3DED1")) +
theme_minimal()
ggplot(perf_measures_long, aes(x = factor(ntrees), y = Value, fill = Measure)) +
geom_bar(stat = "identity", position = "dodge") +
geom_text(aes(label = sprintf("%.2f", Value)),
position = position_dodge(width = 0.8),
vjust = -0.5,
size = 2.5) +
labs(x = "Number of Trees", y = "Value") +
scale_fill_manual(values = c("#99A88C", "#335C67", "#E09F3E", "#E3DED1")) +
theme_minimal()
ggplot(perf_measures_long, aes(x = factor(ntrees), y = Value, fill = Measure)) +
geom_bar(stat = "identity", position = "dodge") +
geom_text(aes(label = sprintf("%.2f", Value)),
position = position_dodge(width = 0.8),
vjust = -0.5,
size = 2) +
labs(x = "Number of Trees", y = "Value") +
scale_fill_manual(values = c("#99A88C", "#335C67", "#E09F3E", "#E3DED1")) +
theme_minimal()
if (!requireNamespace("pacman", quietly = TRUE)) install.packages("pacman"); library(pacman)
pacman::p_load(tidyverse, caret, ranger, tree, glmnet, ISLR, ggplot2, Matrix, dplyr, knitr, kableExtra)
# read the cleaned Alzheimers dataset
alzdata <- readRDS("knnalzdata.RDS")
kable(perf_measures_df, format = "html", digits = 2, caption = "Performance by Number of Trees") %>%
kable_styling(full_width = FALSE, bootstrap_options = c("striped", "hover", "condensed"))
rf_model$bestTune
=======
?nrow
nrow(alzdata)
nrow(train_data)/nrow(alzdata)
library(caret)
library(glmnet)
tune_grid <- expand.grid(alpha = 1, # alpha 1 denotes lasso regression model
lambda = seq(0.001, 0.1, length = 10))
lasso_model <- train(
Diagnosis ~ .,
data = train_data,
method = "glmnet",
tuneGrid = tune_grid,
trControl = modelcv,
)
library(Mlmetrics)
install.packages("MLmetrics")
library(Mlmetrics)
library(MLmetrics)
library(Mlmetrics)
library(MLmetrics)
lasso_model <- train(
Diagnosis ~ .,
data = train_data,
method = "glmnet",
tuneGrid = tune_grid,
trControl = modelcv,
)
# print the best lambda value
print(lasso_model$bestTune)
## lasso confusion matrix
lasso_predictions <- predict(lasso_model, newdata = test_data)
lasso_CM <- confusionMatrix(knn_predictions, test_data$Diagnosis, positive = "Alzheimers")
lasso_CM <- confusionMatrix(lasso_predictions, test_data$Diagnosis, positive = "Alzheimers")
print(lasso_CM)
#with adjusted probabilities
lasso_probs <- predict(lasso_model, newdata = test_data, type = "prob")
lasso_predictions_2 <- ifelse(knn_probs[, "Alzheimers"] > 0.35, "Alzheimers", "No_Alzheimers")
lasso_predictions_2 <- ifelse(lasso_probs[, "Alzheimers"] > 0.35, "Alzheimers", "No_Alzheimers")
lasso_predictions_2 <- factor(lasso_predictions_2, levels = c("No_Alzheimers", "Alzheimers"))
lasso_CM_2 <- confusionMatrix(lasso_predictions_2, test_data$Diagnosis, positive = "Alzheimers", mode = "everything")
lasso(lasso_CM_2)
print(lasso_CM_2)
# scaling train_data and test_data for lasso as lasso is sensitive to unscaled data
train_data <- scale(train_data)
# scaling train_data and test_data for lasso as lasso is sensitive to unscaled data
target <- train_data$target
predictors <- train_data %>% select(-target)
library(dplyr)
# scaling train_data and test_data for lasso as lasso is sensitive to unscaled data
target <- train_data$target
predictors <- train_data %>% select(-target)
scaled_predictors <- as.data.frame(scale(predictors))
predictors <- train_data %>% select(-target)
# scaling train_data and test_data for lasso as lasso is sensitive to unscaled data
target <- train_data$Diagnosis
predictors <- train_data %>% select(-target)
target
predictors <- train_data %>% select(-Diagnosis)
scaled_predictors <- as.data.frame(scale(predictors))
train_data <- cbind(scaled_predictors, Diagnosis=target)
# scaling test data
target <- test_data$Diagnosis
predictors <- test_data %>% select(-Diagnosis)
scaled_predictors <- as.data.frame(scale(predictors))
test_data <- cbind(scaled_predictors, Diagnosis=target)
# Train the model
lasso_model <- train(
Diagnosis ~ .,
data = train_data,
method = "glmnet",
tuneGrid = tune_grid,
trControl = modelcv,
)
# Train the model
lasso_model <- train(
Diagnosis ~ .,
data = train_data,
method = "glmnet",
tuneGrid = tune_grid,
trControl = modelcv,
)
# print the best lambda value
print(lasso_model$bestTune)
## lasso confusion matrix
lasso_predictions <- predict(lasso_model, newdata = test_data)
lasso_CM <- confusionMatrix(lasso_predictions, test_data$Diagnosis, positive = "Alzheimers")
print(lasso_CM)
#with adjusted probabilities
lasso_probs <- predict(lasso_model, newdata = test_data, type = "prob")
lasso_predictions_2 <- ifelse(lasso_probs[, "Alzheimers"] > 0.35, "Alzheimers", "No_Alzheimers")
lasso_predictions_2 <- factor(lasso_predictions_2, levels = c("No_Alzheimers", "Alzheimers"))
lasso_CM_2 <- confusionMatrix(lasso_predictions_2, test_data$Diagnosis, positive = "Alzheimers", mode = "everything")
print(lasso_CM_2)
if (!requireNamespace("pacman", quietly = TRUE)) install.packages("pacman"); library(pacman)
pacman::p_load(tidyverse, caret, ranger, tree, glmnet, ISLR, ggplot2, Matrix, dplyr, knitr, kableExtra, MASS, RColorBrewer, caTools, MLmetrics)
# read the cleaned Alzheimers dataset
alzdata <- readRDS("knnalzdata.RDS")
# Load required libraries
library(readr)   # To read CSV files
library(knitr)   # To format tables in a nice layout
library(kableExtra)
# Read the CSV file into a dataframe
data <- read_csv("dataset_description.csv", show_col_types = FALSE)
# Load required libraries
library(readr)   # To read CSV files
# Read the CSV file into a dataframe
data <- read_csv("dataset_description.csv", show_col_types = FALSE)
>>>>>>> 7c6d8f9d6ad4865b9ede195acf6c9ef366d4d07f
