---
title: "Final Report"
author: "Bijo Varghese, Hong Fu, Jessica Kentwell"
date: "`r format(Sys.Date(), '%B %d, %Y')`" # current date using r 
format:
    html:
        embed-resources: true
        page-layout: full
editor: visual
---

```{r setup echo=FALSE}
if (!requireNamespace("pacman", quietly = TRUE)) install.packages("pacman"); library(pacman)
<<<<<<< HEAD
pacman::p_load(tidyverse, caret, ranger, tree, glmnet, ISLR, ggplot2, Matrix, dplyr, knitr, kableExtra)
=======
pacman::p_load(tidyverse, caret, ranger, tree, glmnet, ISLR, ggplot2, Matrix, MASS, RColorBrewer, caTools)
>>>>>>> jess

# read the cleaned Alzheimers dataset 
alzdata <- readRDS("knnalzdata.RDS")
```

```{r train}
set.seed(5003)
train_index <- createDataPartition(alzdata$Diagnosis, p = 0.7, list = FALSE)
train_data <- alzdata[train_index, ]
test_data <- alzdata[-train_index, ]

modelcv <- trainControl(
  method = "repeatedcv",
  number = 10,
  repeats = 10,
  search = "random", #or grid
  classProbs = TRUE,
  summaryFunction = prSummary, 
  savePredictions = "final",
)


```

<<<<<<< HEAD
## Lasso Regression Model

```{r, lasso}
# lasso regression model requires caret and glmnet packages
library(caret)
library(glmnet)
library(MLmetrics)
library(dplyr)

# scaling train_data and test_data for lasso as lasso is sensitive to unscaled data
target <- train_data$Diagnosis
predictors <- train_data %>% select(-Diagnosis)
scaled_predictors <- as.data.frame(scale(predictors))
train_data <- cbind(scaled_predictors, Diagnosis=target)
# scaling test data 
target <- test_data$Diagnosis
predictors <- test_data %>% select(-Diagnosis)
scaled_predictors <- as.data.frame(scale(predictors))
test_data <- cbind(scaled_predictors, Diagnosis=target)


# setup a range of lambda values 
tune_grid <- expand.grid(alpha = 1, # alpha 1 denotes lasso regression model 
                         lambda = seq(0.001, 0.1, length = 10))

# Train the model
lasso_model <- train(
  Diagnosis ~ ., 
  data = train_data,
  method = "glmnet",
  tuneGrid = tune_grid,
  trControl = modelcv,
  )

# print the best lambda value
print(lasso_model$bestTune)

```

```{r, lasso_performance}
## lasso confusion matrix 
lasso_predictions <- predict(lasso_model, newdata = test_data)
lasso_CM <- confusionMatrix(lasso_predictions, test_data$Diagnosis, positive = "Alzheimers")
print(lasso_CM)

#with adjusted probabilities
lasso_probs <- predict(lasso_model, newdata = test_data, type = "prob")
lasso_predictions_2 <- ifelse(lasso_probs[, "Alzheimers"] > 0.35, "Alzheimers", "No_Alzheimers")
lasso_predictions_2 <- factor(lasso_predictions_2, levels = c("No_Alzheimers", "Alzheimers"))
lasso_CM_2 <- confusionMatrix(lasso_predictions_2, test_data$Diagnosis, positive = "Alzheimers", mode = "everything")
print(lasso_CM_2)


```

```{r}
#regular
#knn_predictions <- predict(knn_model, newdata = test_data)
#knn_CM <- confusionMatrix(knn_predictions, test_data$Diagnosis, positive = "Alzheimers")
#print(knn_CM)
=======
```{r knn, warning=TRUE}
#KNN model train
set.seed(5003)
knn_model <- train(
Diagnosis ~ .,
data = train_data,
method = "knn",
tuneLength = 10,
trControl = modelcv,
preProcess = c("center", "scale"),
metric = "F"
)
```
>>>>>>> jess

```{r lda, warning=FALSE}
#LDA model train
set.seed(5003)
lda_model <- train(
  Diagnosis ~ .,
  data = train_data,
  method = "lda",
  trControl = modelcv,
  preProcess = c("center", "scale"),
  metric = "F"
)
```

```{r warning=FALSE}
#testing rf
set.seed(5003)
rf_model <- train(Diagnosis ~ ., data = train_data, method = "rf", tuneLength = 10, trControl = modelcv, preProcess = c("center", "scale"), metric = "F")
#testing lasso
set.seed(5003)
lasso_model <- train(Diagnosis ~ ., data = train_data, method = "glmnet", tuneLength = 10, trControl = modelcv,  preProcess = c("center", "scale"), metric = "F")
```

```{r resamples}
#this is just for cross validated data - now we can go back and choose the metric we want to use and keep it consistent. F1 i think is the best. 
resamples_results <- resamples(list(KNN = knn_model, LDA = lda_model, RF = rf_model, Lasso = lasso_model))
summary(resamples_results)

bwplot(resamples_results, metric = c("Recall", "F1", "AUC"))
dotplot(resamples_results, metric = c("Recall", "F1", "AUC"))
```

```{r tuning}
print(lasso_model$bestTune)

print(rf_model$bestTune)
print(knn_model$bestTune)
print(lda_model$bestTune)
```

```{r knn_predict}
#without threshold adjustment
knn_probs <- predict(knn_model, newdata = test_data, type = "prob")
knn_preds <- predict(knn_model, newdata = test_data)
knn_CM <- confusionMatrix(knn_preds, test_data$Diagnosis, positive = "Alzheimers", mode = "everything")
print(knn_CM)
```

```{r knn_predict_2}
knn_preds_2 <- ifelse(knn_probs[, "Alzheimers"] > 0.35, "Alzheimers", "No_Alzheimers")
knn_preds_2 <- factor(knn_preds_2, levels = c("No_Alzheimers", "Alzheimers"))
knn_CM_2 <- confusionMatrix(knn_preds_2, test_data$Diagnosis, positive = "Alzheimers", mode = "everything")
print(knn_CM_2)
```

```{r lda_predict}
#without threshold adjustment
lda_probs <- predict(lda_model, newdata = test_data, type = "prob")
lda_preds <- predict(lda_model, newdata = test_data)
lda_CM <- confusionMatrix(lda_preds, test_data$Diagnosis, positive = "Alzheimers", mode = "everything")
print(lda_CM)
```

```{r lda_predict_2}
lda_prob_predictions <- predict(lda_model, newdata = test_data, type = "prob")
#new threshold
new_prob <- 0.35
lda_predictions_2 <- ifelse(lda_prob_predictions$Alzheimers >= new_prob, "Alzheimers", "No_Alzheimers")
lda_predictions_2 <- factor(lda_predictions_2, levels = levels(test_data$Diagnosis))
lda_CM_2 <- confusionMatrix(lda_predictions_2, test_data$Diagnosis, positive = "Alzheimers", mode = "everything")
print(lda_CM_2)
```

## Random Forest

```{r rfB, message=FALSE, echo=FALSE, warning=FALSE}
ntree_seq <- c(1, 50, 100, 250, 500)
max.ntree_seq <- max(ntree_seq)
test_diagnosis <- test_data[["Diagnosis"]]



rand.forest.function <- function(x) { 
  
  rf_model <- train(
  Diagnosis ~ .,              
  data = train_data,
  method = "rf",
  trControl = modelcv,
  tuneGrid = expand.grid(.mtry = sqrt(ncol(train_data) - 1)), 
  ntree = x
  )
  
  predict_rf <- predict(rf_model, newdata = test_data, type = "prob")
  predicted_labels <- ifelse(predict_rf[, "Alzheimers"] > 0.35, "Alzheimers", "No_Alzheimers") |> as.factor()
  CM <- confusionMatrix(test_diagnosis, predicted_labels, positive = "Alzheimers")
  Sensit <- CM$byClass[["Sensitivity"]]
  Specif <- CM$byClass[["Specificity"]]
  Accura <- CM$overall[["Accuracy"]]
  TP <- CM$table["Alzheimers", "Alzheimers"]
  FP <- CM$table["Alzheimers", "No_Alzheimers"]
  FN <- CM$table["No_Alzheimers", "Alzheimers"]
  precision <- TP / (TP + FP)
  recall <- TP / (TP + FN)
  F1 <- 2 * (precision * recall) / (precision + recall)
  Performance_measures <- list(ntrees = x, Sensitivity = Sensit, Specificity = Specif, Accuracy = Accura, F1 = F1)
  }
perf_measures <- map(ntree_seq, rand.forest.function)
sensitivities <- map_dbl(perf_measures, "Sensitivity")
plot_data <- data.frame(ntree_seq, sensitivities)
ggplot(plot_data, aes(x = ntree_seq, y = sensitivities)) +
  geom_line() +
  geom_point() + 
  geom_text(aes(label = round(sensitivities, 4)), 
            vjust = -0.5, 
            color = "black", 
            size = 3.5) +
  labs(x = "Number of Trees", y = "Sensitivity") +
  theme_minimal()


perf_measures_df <- bind_rows(perf_measures)

perf_measures_long <- perf_measures_df %>%
  pivot_longer(cols = c(Sensitivity, Specificity, Accuracy, F1),
               names_to = "Measure",
               values_to = "Value")

ggplot(perf_measures_long, aes(x = factor(ntrees), y = Value, fill = Measure)) +
  geom_bar(stat = "identity", position = "dodge") +
  geom_text(aes(label = sprintf("%.2f", Value)), 
            position = position_dodge(width = 0.8), 
            vjust = -0.5, 
            size = 2.5) +
  labs(x = "Number of Trees", y = "Value") +
  scale_fill_manual(values = c("#99A88C", "#335C67", "#E09F3E", "#E3DED1")) + 
  theme_minimal()

```

**Performance by number of trees**
``` {r foresttable, echo=FALSE, message=FALSE}
kable(perf_measures_df, format = "html", digits = 2) %>%
  kable_styling(full_width = FALSE, bootstrap_options = c("striped", "hover", "condensed"))
```

### Overview of the problem

### Dataset Description

### Initial Data Analysis / Visualisation of the data

### Feature Engineering

### Classification Algorithms used

Repeat cross-validation

Resamples - chose F1

Hyperparameter tuning per model

Final model specs:

KNN best tuned k =

RF best tuned mtry = and ntree =

Lasso best tuned lambda = and alpha =

LDA (no hyperparameter tuning).

### Classification Performance Evaluation

Threshold adjustment

Confusion matrix heatmap for each model as well as metrics: Recall and F1.

ROC curves for each model.

### Conclusion

```{r}
colAUC(knn_preds, test_data$Diagnosis, plotROC = TRUE)
```

```{r}
library(pROC)
roc_knn <- roc(test_data$Diagnosis, knn_probs[, "Alzheimers"])
plot(roc_knn, col="green", main="KNN ROC")
roc_lda <- roc(test_data$Diagnosis, lda_probs[, "Alzheimers"])
plot(roc_lda, col="blue", main="LDA ROC")
```
