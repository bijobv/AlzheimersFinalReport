---
title: "Final Report"
author: "Bijo Varghese, Hong Fu, Jessica Kentwell"
date: "`r format(Sys.Date(), '%B %d, %Y')`" # current date using r 
format:
    html:
        embed-resources: true
        page-layout: full
editor: visual
---

```{r setup echo=FALSE}
if (!requireNamespace("pacman", quietly = TRUE)) install.packages("pacman"); library(pacman)
pacman::p_load(tidyverse, caret, ranger, tree, glmnet, ISLR, ggplot2, Matrix, MASS, RColorBrewer, )

#alzdata <- readRDS("alzdata.RDS")
alzdata <- readRDS("knnalzdata.RDS")
```

```{r train}
set.seed(5003)
train_index <- createDataPartition(alzdata$Diagnosis, p = 0.7, list = FALSE)
train_data <- alzdata[train_index, ]
test_data <- alzdata[-train_index, ]

modelcv <- trainControl(
  method = "repeatedcv",
  number = 10,
  repeats = 10,
  search = "random", #or grid
  classProbs = TRUE,
  summaryFunction = prSummary, 
  savePredictions = "final",
)


```

```{r knn, warning=TRUE}
#KNN model train
set.seed(5003)
knn_model <- train(
Diagnosis ~ .,
data = train_data,
method = "knn",
tuneLength = 10,
trControl = modelcv,
preProcess = c("center", "scale"),
metric = "F"
)
```

```{r lda, warning=FALSE}
#LDA model train
set.seed(5003)
lda_model <- train(
  Diagnosis ~ .,
  data = train_data,
  method = "lda",
  trControl = modelcv,
  preProcess = c("center", "scale"),
  metric = "F"
)
```

```{r warning=FALSE}
#testing rf
set.seed(5003)
rf_model <- train(Diagnosis ~ ., data = train_data, method = "rf", tuneLength = 10, trControl = modelcv, preProcess = c("center", "scale"), metric = "F")
#testing lasso
set.seed(5003)
lasso_model <- train(Diagnosis ~ ., data = train_data, method = "glmnet", tuneLength = 10, trControl = modelcv,  preProcess = c("center", "scale"), metric = "F")
```

```{r resamples}
#this is just for cross validated data - now we can go back and choose the metric we want to use and keep it consistent. F1 i think is the best. 
resamples_results <- resamples(list(KNN = knn_model, LDA = lda_model, RF = rf_model, Lasso = lasso_model))
summary(resamples_results)

bwplot(resamples_results, metric = c("Recall", "F1", "AUC"))
dotplot(resamples_results, metric = c("Recall", "F1", "AUC"))
```

```{r tuning}
print(lasso_model$bestTune)

print(rf_model$bestTune)
print(knn_model$bestTune)
print(lda_model$bestTune)
```

### Overview of the problem

### Dataset Description

### Initial Data Analysis / Visualisation of the data

### Feature Engineering

### Classification Algorithms used

Repeat cross-validation

Resamples - chose F1

Hyperparameter tuning per model

Final model specs:

KNN best tuned k =

RF best tuned mtry = and ntree =

Lasso best tuned lambda = and alpha =

LDA (no hyperparameter tuning).

### Classification Performance Evaluation

Threshold adjustment

Confusion matrix heatmap for each model as well as metrics: Recall and F1.

ROC curves for each model.

### Conclusion

```{r}
library(pROC)
roc_knn <- roc(test_data$Diagnosis, knn_probs[, "Alzheimers"])
plot(roc_knn, col="green")
roc_lda <- roc(test_data$Diagnosis, lda_probs[, "Alzheimers"])
plot(lda_knn, col="blue")
```
